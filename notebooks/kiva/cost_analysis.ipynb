{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding system path\n",
    "import sys, pathlib\n",
    "sys.path.append(str(pathlib.Path.cwd().parent.parent))\n",
    "# sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to show warnings only once\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up displays\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from dash import Dash,html,dcc,Input,Output\n",
    "app = Dash(__name__)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from tabulate import tabulate\n",
    "color_scheme=[\"red\",\"blue\",\"green\",\"orange\",\"purple\",\"brown\",\"pink\",\"gray\",\"olive\",\"cyan\",\"darkviolet\",\"goldenrod\",\"darkgreen\",\"chocolate\",\"lawngreen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dash import Dash,html,dcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##center allign all the figure outputs.\n",
    "# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "# from IPython.display import display, HTML\n",
    "# from plotly.graph_objs import *\n",
    "# import numpy as np\n",
    "# init_notebook_mode(connected=True)\n",
    "\n",
    "# display(HTML(\"\"\"\n",
    "# <style>\n",
    "# .output {\n",
    "#     display: flex;\n",
    "#     align-items: center;\n",
    "#     text-align: center;\n",
    "# }\n",
    "# </style>\n",
    "# \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up autoreload for libs\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport optiml.queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize connection to Snowflake and set analysis date\n",
    "from optiml.connection import SnowflakeConnConfig\n",
    "connection = SnowflakeConnConfig(accountname='jg84276.us-central1.gcp',warehousename=\"XSMALL_WH\").create_connection()\n",
    "# Initialize local environment\n",
    "import os\n",
    "cache_dir = os.path.expanduser('~/data/kiva')\n",
    "# Initialize query library\n",
    "from optiml.queries import SNFLKQuery\n",
    "qlib = SNFLKQuery(connection, 'KIV', cache_dir)\n",
    "sdate = '2022-01-27'\n",
    "edate = '2022-10-12'\n",
    "# Most recent rolling month that we have data for\n",
    "# print(f\"The analysis is carried our for date range {sdate} to {edate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total cost breakdown "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis setup\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "* Analysis date range: '2022-09-12' to '2022-10-12'\n",
    "\n",
    "* Type of Snowflake account: Standard Edition\n",
    "\n",
    "* Credit to dollar conversion: `$`2 per credit\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost by usage category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = qlib.total_cost_breakdown_ts(sdate, edate)\n",
    "df = df.fillna('Unassigned')\n",
    "# df.to_csv('/home/manas/DS_data/breakdown.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_usage_category = df.groupby(\"category_name\").sum(\"numeric_only\").reset_index()\n",
    "df_by_usage_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_usage_category = df.groupby(\"category_name\").sum(\"numeric_only\").reset_index()\n",
    "df_by_usage_category.loc[len(df.index)] = ['Total', df_by_usage_category['credits'].sum(), df_by_usage_category['dollars'].sum()]\n",
    "df_by_usage_category = df_by_usage_category.round(2)\n",
    "print(tabulate(df_by_usage_category, headers='keys', tablefmt='rounded_outline', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie charts for total cost breakdown\n",
    "## Remove the last row of totals for the plot\n",
    "df_by_usage_category.reset_index(inplace=True)\n",
    "df_by_usage_category.drop(columns=[\"index\"], inplace=True)\n",
    "df_by_usage_category = df_by_usage_category.drop(len(df_by_usage_category)-1) \n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    specs=[[{\"type\": \"pie\"},{\"type\": \"pie\"}]],\n",
    "    subplot_titles=(\"Dollars\", \"Credits\")\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Pie(labels=df_by_usage_category['category_name'].tolist(), values=df_by_usage_category['dollars'].tolist(),name=\"Dollars\", rotation=45, marker_colors=color_scheme),row=1,col=1)\n",
    "fig.add_trace(go.Pie(labels=df_by_usage_category['category_name'].tolist(), values=df_by_usage_category['credits'].tolist(),name='Credits', rotation=45, marker_colors=color_scheme),row=1,col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Breakdown of total cost by usage category\",\n",
    "        'y':0.1,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'bottom'})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost by usage category timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_category_ts = df.groupby(['category_name','hourly_start_time']).sum('numeric_only').reset_index()\n",
    "fig = px.area(df_by_category_ts, x=\"hourly_start_time\", y=\"dollars\", color=\"category_name\",color_discrete_sequence=color_scheme)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compute = df_by_category_ts[df_by_category_ts[\"category_name\"] == \"Compute\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_consumption = df_compute.mean()\n",
    "max_consumption = df_compute.loc[df_compute['credits'].idxmax()]\n",
    "min_consumption = df_compute.loc[df_compute['credits'].idxmin()]\n",
    "\n",
    "print('Avg. consumption:')\n",
    "print('-----------------')\n",
    "print(avg_consumption)\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Max. consumption:')\n",
    "print('-----------------')\n",
    "print(max_consumption)\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Min. consumption:')\n",
    "print('-----------------')\n",
    "print(min_consumption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "#### Compute\n",
    "* Compute consumes > 95% of the budget. This is as expected.  \n",
    "* The average compute consumption is Credits: 12.69, Dollars: `$`25.38, with usage peaks typically at 9 am and 2 pm. \n",
    "* The typical compute through the night is non-zero at ~ 10 credits. \n",
    "* The nightime compute consumption is flat till 23rd but becomes noisy starting 24th.\n",
    "* There is an increase in nightime consumption on 9th and 10th of ~30% which reverts to usual pattern subsequently. \n",
    "\n",
    "#### Cloud Services\n",
    "* Cloud services in aggregate consume < 10% of the budget - which is consistent with no over charges if this is true for each warehouse on an hourly basis.\n",
    "* The overall timeseries for credit consumption of cloud services is also < 10% of compute.\n",
    "\n",
    "#### Storage\n",
    "* Storage cost is a small fraction of the `$` budget. Storage is charged by flat `$` amount per TB starting at `$`23/TB. For the timeseries we have spread that evenly through the day.\n",
    "* Storage costs are almost flat during the period.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions and Recommendations\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "* Analyze Cloud Services credit consumption on an hourly basis at a warehouse level to make sure no overages hourly by warehouse.\n",
    "* Investigate noisy night time usage after Sept 23.\n",
    "* Investigate increased baseline consumption that occurs on 10th and 11th Oct.\n",
    "* Evaluate the system for compute bottlenecks and queue lengths for - warehouses, tasks, and queries at 9 am and 2 pm due to usage spikes.\n",
    "* Based on cost we expect ~300 GB storage is being used. Verify this number for consistency.\n",
    "* Set up a time varying resource monitor on the account level based on these usage patterns to flag any anomalous usage. Usage monitoring set naively:\n",
    "    * Will not be proactive about cost containment \n",
    "    * Can generate false positives/negatives causing nuisance alerts/shutdowns. \n",
    "* Evaluate opportunities for savings through:\n",
    "    * Dithering peak workloads to alternate times.\n",
    "    * Reducing weekend consumption \n",
    "    * Dithering jobs to or reducing night time consumption\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = qlib.cost_by_user_ts(sdate, edate)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_user = df.groupby(['user_name']).sum('numeric_only').reset_index()\n",
    "df_by_user = df_by_user.round(2)\n",
    "df_by_user.loc[len(df.index)] = ['Total', df_by_user['credits'].sum(), df_by_user['dollars'].sum()]\n",
    "print(tabulate(df_by_user, headers='keys', tablefmt='rounded_outline', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_user.drop(df_by_user.tail(1).index,inplace=True)\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    specs=[[{\"type\": \"pie\"},{\"type\": \"pie\"}]],\n",
    "    subplot_titles=(\"Dollars\", \"Credits\")\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Pie(labels=df_by_user['user_name'].tolist(), values=df_by_user['dollars'].tolist(),name=\"Dollars\", rotation=45,marker_colors=color_scheme),row=1,col=1)\n",
    "fig.add_trace(go.Pie(labels=df_by_user['user_name'].tolist(), values=df_by_user['credits'].tolist(),name='Credits', rotation=45,marker_colors=color_scheme),row=1,col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Breakdown of total cost by user\",\n",
    "        'y':0.1,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'bottom'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_user_ts = df.groupby(['user_name','hourly_start_time']).sum('numeric_only').reset_index()\n",
    "fig = px.area(df_by_user_ts, x=\"hourly_start_time\", y=\"credits\", color=\"user_name\",color_discrete_sequence=color_scheme)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "* User GREGORYW incurs ~ 30% of the costs at ~ 1385 credits.\n",
    "* Users VERTX_PROD and DBT_PROD have next highest consumption at ~ 20% and ~ 894 credits.\n",
    "* Users DBT_DEV and ROBS spend the least value of dollars and credits compared to other users.\n",
    "* User SNOWFLAKE includes costs associated with storage, and Snowflake related functions - this makes total_cost_breakdown numbers self consistent with cost_by_user.\n",
    "* The overall compute consumption patterns through the day are similar to total_cost_breakdown.\n",
    "* There is an increase in credit usage on the 8th, 9th and 10th of October during off peak hours (~ 8 pm - 8 am) which can be attributed to the following users:\n",
    "    * DBT_DEV: +100% \n",
    "    * GREGORYW: +30%\n",
    "    * Unassigned: +100%\n",
    "\n",
    "* The increased noisiness in usage starting 24th is attributable to users ROBS and Unassigned. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions and Recommendations\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "* Queries for following users should be tagged better - so they can be attributed to organizations/projects/R&D.:\n",
    "    * GREGORYW\n",
    "    * Unassigned\n",
    "* User roles associated with automated jobs should be tagged and have user account level resource monitoring around them based on historical usage: \n",
    "    * VERTX_PROD\n",
    "    * DBT_PROD\n",
    "* Notify the admin 8th - 10th that users GREGORYW, Unassigned and DBT_DEV have increased credit consumption during off peak hours (~ 8 pm - 8 am) \n",
    "* Set up a time varying resource monitor at account and user level based on usage patterns to flag any anomalous usage.    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost by warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns results only for ACCOUNTADMIN role or any other role that has been granted MONITOR USAGE global privilege\n",
    "# So results consisten with Greg's usage\n",
    "df = qlib.cost_by_wh_ts(sdate, edate)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_wh = df.groupby(['warehouse_name']).sum('numeric_only').reset_index()\n",
    "df_by_wh = df_by_wh.round(2)\n",
    "df_by_wh.loc[len(df.index)] = ['Total', df_by_wh['credits'].sum(), df_by_wh['dollars'].sum(),  df_by_wh['cloud_services_credits'].sum(), df_by_wh['cloud_services_dollars'].sum()]\n",
    "print(tabulate(df_by_wh, headers='keys', tablefmt='rounded_outline', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last row of totals for the plot\n",
    "df_by_wh.drop(df_by_wh.tail(1).index,inplace=True)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=1,\n",
    "    specs=[[{\"type\": \"pie\"}]],\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Pie(labels=df_by_wh['warehouse_name'].tolist(), values=df_by_wh['dollars'].tolist(),name='dollars',marker_colors=color_scheme),row=1,col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Breakdown of total cost by warehouse\",\n",
    "        'y':0.1,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_wh_ts = df.groupby(['warehouse_name','hourly_start_time']).sum('numeric_only').reset_index()\n",
    "# df_by_wh_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: Investigate why tunring off cloud services only makes daily refresh plot jump in some points\n",
    "fig = px.area(df_by_wh_ts, x=\"hourly_start_time\", y=\"credits\", color=\"warehouse_name\",color_discrete_sequence=color_scheme)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "* Total credit consumption for all the warehouses combined is lower compared to total credit consumption overall and total credit consumption for all users combined.\n",
    "    * This is because [warehouse metering history](https://docs.snowflake.com/en/sql-reference/functions/warehouse_metering_history.html) returns results only for the ACCOUNTADMIN role or any role that has been explicitly granted the MONITOR USAGE global privilege. \n",
    "    * #TODO: @Saravana - why did Snowflake set it up this way?\n",
    "  \n",
    "* PROD_WH incurs highest and > 50% of the costs at ~ 3110 credits.\n",
    "* DEV_WH consumes next highest ~30% at ~ 1872 credits.\n",
    "* DAILY_REFRESH_WH and ML_WH consume 14.6% and 3.6% respectively.\n",
    "\n",
    "* The increased credit consumption from 8th-10th Oct. is completely in DEV_WH where credit consumption increases by 200%. \n",
    "    * This increase is similar in magnitude to 11-2 pm everyday for this WH - investigate if it was the same process run intentionally or not.\n",
    "    \n",
    "* PROD_WH shows a +200% increase on 1st Oct. from 1-5 pm which shows as a spike in other views as well but was not as prominent.\n",
    "    \n",
    "* Fewer credits consumed by DAILY_REFRESH_WH on Monday and Tuesday - would have expected that to be for weekend.\n",
    "    \n",
    "* Increased noisiness starting 24th is almost entirely coming from ML_WH.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions and Recommendations\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "* For better visibility grant MONITOR USAGE global privilege to all users. (Or look for alternatives to make warehouse credit consumption consistent with total credit consumption).\n",
    "* Set WH level alerts for each WH - especially for DEV_WH and PROD_WH\n",
    "* Tag jobs by function in PROD_WH and DEV_WH\n",
    "* Set up a time varying resource monitor at warehouse level based on usage patterns to flag any anomalous usage.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost by Partner Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=qlib.cost_by_partner_tool_ts(sdate, edate)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_pt = df.groupby(['client_application_name']).sum('numeric_only').reset_index()\n",
    "df_by_pt = df_by_pt.round(2)\n",
    "df_by_pt.loc[len(df.index)] = ['Total', df_by_pt['approximate_credits_used'].sum()]\n",
    "print(tabulate(df_by_pt, headers='keys', tablefmt='rounded_outline', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last row of totals for the plot\n",
    "df_by_pt.drop(df_by_pt.tail(1).index,inplace=True)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=1,\n",
    "    specs=[[{\"type\": \"pie\"}]],\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Pie(labels=df_by_pt['client_application_name'].tolist(), values=df_by_pt['approximate_credits_used'].tolist(),name='credits',marker_colors=color_scheme, rotation=45),row=1,col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Breakdown of total cost by partner tools\",\n",
    "        'y':0.1,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_pt_ts = df.groupby(['client_application_name','hourly_start_time']).sum('numeric_only').reset_index()\n",
    "df_by_pt_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(df_by_pt_ts, x=\"hourly_start_time\", y=\"approximate_credits_used\", color=\"client_application_name\",color_discrete_sequence=color_scheme)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analyze if a specific client tool is attached with a specific warehouse. For each warehouse what percentage of credits are used by which tool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_pt_wh_ts = df.groupby(['client_application_name', 'warehouse_name','hourly_start_time']).sum('numeric_only').reset_index()\n",
    "df_by_pt_wh_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_pt_wh_ts[\"client_application_warehouse_name\"] = df_by_pt_wh_ts[\"client_application_name\"] + \"_\" + df_by_pt_wh_ts[\"warehouse_name\"]\n",
    "df_by_pt_wh_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_pt_wh_ts = df_by_pt_wh_ts.groupby([\"client_application_warehouse_name\",\"hourly_start_time\"]).sum(\"numeric_only\").reset_index()\n",
    "df_by_pt_wh_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(df_by_pt_wh_ts, x=\"hourly_start_time\", y=\"approximate_credits_used\", color=\"client_application_warehouse_name\",color_discrete_sequence=color_scheme)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "* Total credit consumption for all the warehouses combined is lower compared to total credit consumption overall and total credit consumption for all users combined.\n",
    "    * This is because [warehouse metering history](https://docs.snowflake.com/en/sql-reference/functions/warehouse_metering_history.html) returns results only for the ACCOUNTADMIN role or any role that has been explicitly granted the MONITOR USAGE global privilege. \n",
    "  \n",
    "* PROD_WH incurs highest and > 50% of the costs at ~ 3110 credits.\n",
    "* DEV_WH consumes next highest ~30% at ~ 1872 credits.\n",
    "* DAILY_REFRESH_WH and ML_WH consume 14.6% and 3.6% respectively.\n",
    "\n",
    "* The increased credit consumption from 8th-10th Oct. is completely in DEV_WH where credit consumption increases by 200%. \n",
    "    * This increase is similar in magnitude to 11-2 pm everyday for this WH - investigate if it was the same process run intentionally or not.\n",
    "    \n",
    "* PROD_WH shows a +200% increase on 1st Oct. from 1-5 pm which shows as a spike in other views as well but was not as prominent.\n",
    "    \n",
    "* Fewer credits consumed by DAILY_REFRESH_WH on Monday and Tuesday - would have expected that to be for weekend.\n",
    "    \n",
    "* Increased noisiness starting 24th is almost entirely coming from ML_WH.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions and Recommendations\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "* For better visibility grant MONITOR USAGE global privilege to all users. (Or look for alternatives to make warehouse credit consumption consistent with total credit consumption).\n",
    "* Set WH level alerts for each WH - especially for DEV_WH and PROD_WH\n",
    "* Tag jobs by function in PROD_WH and DEV_WH\n",
    "* Set up a time varying resource monitor at warehouse level based on usage patterns to flag any anomalous usage.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Implement cost of data transfers query using https://docs.snowflake.com/en/user-guide/cost-exploring-data-transfer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "fcbd4ad66d969ea49516a1cf27383420b67e9e950ebdd1bbb64e01b736f968b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
