{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding system path\n",
    "import sys, pathlib, os\n",
    "sys.path.append(str(pathlib.Path.cwd().parent.parent))\n",
    "# sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to show warnings only once\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup connection to DWH\n",
    "# customer = 'KIVA'\n",
    "# schema = 'KIVA_PROD.OPTIML'\n",
    "customer = 'OPTIML' # Use this for testing\n",
    "schema = 'KIV.ACCOUNT_USAGE' # Use this for testing\n",
    "username = customer + '_USERNAME'\n",
    "password = customer + '_PASSWORD'\n",
    "account = customer + '_ACCOUNT'\n",
    "warehouse = customer + '_WAREHOUSE'\n",
    "\n",
    "user = os.getenv(username)\n",
    "password = os.getenv(password)\n",
    "account = os.getenv(account)\n",
    "warehouse = os.getenv(warehouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup pandas\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import pickle\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from tabulate import tabulate\n",
    "color_scheme=[\"red\",\"blue\",\"green\",\"orange\",\"purple\",\"brown\",\"pink\",\"gray\",\"olive\",\"cyan\",\"darkviolet\",\"goldenrod\",\"darkgreen\",\"chocolate\",\"lawngreen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize connection to Snowflake and set analysis date\n",
    "from optiml.connection import SnowflakeConnConfig\n",
    "connection = SnowflakeConnConfig(username=user,password=password,accountname=account).create_connection()\n",
    "\n",
    "# Initialize query library\n",
    "from optiml.backend.cost_profile import CostProfile, get_previous_dates\n",
    "cqlib = CostProfile(connection, schema)\n",
    "\n",
    "# Initialize dates\n",
    "import datetime \n",
    "# edate = datetime.date.today() - datetime.timedelta(days=1)\n",
    "# sdate = edate - datetime.timedelta(days=8)\n",
    "edate = datetime.datetime.strptime('2022-10-04', '%Y-%m-%d').date()\n",
    "sdate = datetime.datetime.strptime('2022-09-29', '%Y-%m-%d').date()\n",
    "# edate = datetime.datetime.strptime('2022-10-12', '%Y-%m-%d').date()\n",
    "# sdate = datetime.datetime.strptime('2022-10-05', '%Y-%m-%d').date()\n",
    "# edate = str(edate)\n",
    "# sdate = str(sdate)\n",
    "\n",
    "print('Customer:', customer)\n",
    "print('Schema:', schema)\n",
    "print(str(sdate), str(edate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up autoreload for libs\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport optiml.backend.cost_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total cost breakdown "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost by usage category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get data\n",
    "df = cqlib.total_cost_breakdown_ts(sdate, edate)\n",
    "df = df.fillna('Unassigned')\n",
    "## Get usage for past week\n",
    "df_by_usage_category = df.groupby(\"category_name\").sum(\"numeric_only\").reset_index()\n",
    "df_by_usage_category.loc[len(df_by_usage_category.index)] = ['Total', df_by_usage_category['credits'].sum(), df_by_usage_category['dollars'].sum()]\n",
    "df_by_usage_category = df_by_usage_category.round(2)\n",
    "\n",
    "## Get usage for previous week as a predictive sanity check\n",
    "p1_sdate, p1_edate = get_previous_dates(sdate, edate, 1)\n",
    "df_prev = cqlib.total_cost_breakdown_ts(p1_sdate, p1_edate)\n",
    "df_prev = df_prev.fillna('Unassigned')\n",
    "df_by_usage_category_prev = df_prev.groupby(\"category_name\").sum(\"numeric_only\").reset_index()\n",
    "df_by_usage_category_prev.loc[len(df_by_usage_category_prev.index)] = ['Total', df_by_usage_category_prev['credits'].sum(), \n",
    "                                                                       df_by_usage_category_prev['dollars'].sum()]\n",
    "## Get percentage change since previous week\n",
    "df_by_usage_category_prev = df_by_usage_category_prev.round(2)\n",
    "df_by_usage_category.set_index('category_name',inplace=True)\n",
    "df_by_usage_category_prev.set_index('category_name',inplace=True)\n",
    "df_by_usage_category_prev.rename(columns={\"credits\": \"credits_previous_week\", \"dollars\": \"dollars_previous_week\"}, inplace=True)\n",
    "\n",
    "df_by_usage_category = pd.concat([df_by_usage_category_prev, df_by_usage_category], axis=1)\n",
    "df_by_usage_category.reset_index(inplace=True)\n",
    "df_by_usage_category[\"pct_change_dollars\"] = round((df_by_usage_category[\"dollars\"]-df_by_usage_category[\"dollars_previous_week\"])/df_by_usage_category[\"dollars_previous_week\"]*100,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get table for this week and previous week with percentage change\n",
    "print('Category: Credit and dollar consumption trends')\n",
    "print('----------------------------------------------')\n",
    "print(tabulate(df_by_usage_category, headers='keys', tablefmt='rounded_outline', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pie charts for total cost breakdown\n",
    "df_by_usage_category.reset_index(inplace=True)\n",
    "df_by_usage_category.drop(columns=[\"index\"], inplace=True)\n",
    "df_by_usage_category = df_by_usage_category.drop(len(df_by_usage_category)-1) \n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    specs=[[{\"type\": \"pie\"},{\"type\": \"pie\"}]],\n",
    "    subplot_titles=(\"Dollars\", \"Credits\")\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Pie(labels=df_by_usage_category['category_name'].tolist(), values=df_by_usage_category['dollars'].tolist(),name=\"Dollars\", \n",
    "                     rotation=45, marker_colors=color_scheme),row=1,col=1)\n",
    "fig.add_trace(go.Pie(labels=df_by_usage_category['category_name'].tolist(), values=df_by_usage_category['credits'].tolist(),name='Credits',\n",
    "                     rotation=45, marker_colors=color_scheme),row=1,col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Total cost by usage category\",\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Timeseries\n",
    "## TODO: Use this to make recommendations for resource monitors - \n",
    "## 1) Total for a week \n",
    "## 2) For each day based on historic patterns\n",
    "df_by_category_ts = df.groupby(['category_name','hourly_start_time']).sum('numeric_only').reset_index()\n",
    "fig = px.area(df_by_category_ts, x=\"hourly_start_time\", y=\"dollars\", color=\"category_name\",color_discrete_sequence=color_scheme)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Timeseries of cost by usage category\",\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    xaxis_title=\"Hourly start time (UTC)\",\n",
    "    yaxis_title=\"US Dollars\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_compute = df_by_category_ts[df_by_category_ts[\"category_name\"] == \"Compute\"].round(2)\n",
    "# avg_consumption = df_compute.mean().round(2)\n",
    "# max_consumption = df_compute.loc[df_compute['credits'].idxmax()]\n",
    "# max_consumption.drop(\"category_name\", inplace=True)\n",
    "# min_consumption = df_compute.loc[df_compute['credits'].idxmin()]\n",
    "# min_consumption.drop(\"category_name\", inplace=True)\n",
    "\n",
    "# print('Avg. hourly consumption:')\n",
    "# print('-----------------')\n",
    "# print(avg_consumption)\n",
    "\n",
    "# print('')\n",
    "\n",
    "# print('Max. hourly consumption:')\n",
    "# print('-----------------')\n",
    "# print(max_consumption)\n",
    "\n",
    "# print('')\n",
    "\n",
    "# print('Min. hourly consumption:')\n",
    "# print('-----------------')\n",
    "# print(min_consumption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get usage for the past week\n",
    "df = cqlib.cost_by_user_ts(sdate, edate)\n",
    "df_by_user = df.groupby(['user_name']).sum('numeric_only').reset_index()\n",
    "df_by_user = df_by_user.round(2)\n",
    "\n",
    "## Get usage for previous week as a predictive sanity check\n",
    "df_prev = cqlib.cost_by_user_ts(p1_sdate, p1_edate)\n",
    "df_by_user_prev = df_prev.groupby(['user_name']).sum('numeric_only').reset_index()\n",
    "df_by_user_prev = df_by_user_prev.round(2)\n",
    "df_by_user_prev.rename(columns={\"approximate_credits\": \"approximate_credits_previous_week\"}, inplace=True)\n",
    "\n",
    "\n",
    "## Get percentage change since previous week\n",
    "df_by_user.set_index('user_name',inplace=True)\n",
    "df_by_user_prev.set_index('user_name',inplace=True)\n",
    "df_by_user = pd.concat([df_by_user_prev, df_by_user], axis=1)\n",
    "df_by_user.reset_index(inplace=True)\n",
    "df_by_user.loc[len(df_by_user.index)] = ['Total', \\\n",
    "                                              df_by_user['approximate_credits_previous_week'].sum(), \\\n",
    "                                              df_by_user['approximate_credits'].sum()]\n",
    "\n",
    "df_by_user.fillna({'user_name':'Unassigned',\\\n",
    "                   'approximate_credits_previous_week':0,\\\n",
    "                   'approximate_credits':0\n",
    "                  }, inplace=True)\n",
    "\n",
    "\n",
    "df_by_user[\"pct_change_credits\"] = round((df_by_user[\"approximate_credits\"]\\\n",
    "                                          -df_by_user[\"approximate_credits_previous_week\"])\\\n",
    "                                         /df_by_user[\"approximate_credits_previous_week\"]*100,2)\n",
    "\n",
    "print('Users: Credit consumption trends')\n",
    "print('--------------------------------')\n",
    "print(tabulate(df_by_user, headers='keys', tablefmt='rounded_outline', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_user = df_by_user[[\"user_name\", \"approximate_credits\"]]\n",
    "df_by_user[\"percent_usage\"] = df_by_user[\"approximate_credits\"]/df_by_user[df_by_user[\"user_name\"]==\"Total\"][\"approximate_credits\"].values[0]*100\n",
    "df_by_user[\"percent_usage\"] = df_by_user[\"percent_usage\"].round(3)\n",
    "idx_low_usage_users = df_by_user.loc[df_by_user[\"percent_usage\"]<1.00].sum(axis=0,numeric_only=True)\n",
    "df_low_usage_users = df_by_user.loc[df_by_user[\"percent_usage\"] < 1.00].reset_index(drop=True)\n",
    "print('List of low usage users (<1% of credits) with usage (Current month)')\n",
    "print('-------------------------------------------------------------------')\n",
    "print(tabulate(df_low_usage_users, headers='keys', tablefmt='rounded_outline', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Group low usage users together\n",
    "df_by_user = df_by_user.loc[df_by_user[\"percent_usage\"] > 1.00].reset_index(drop=True)\n",
    "df_by_user.loc[len(df_by_user)-1.5] = [\"Low_usage_users\",\\\n",
    "                                       idx_low_usage_users[\"approximate_credits\"],\\\n",
    "                                       idx_low_usage_users[\"percent_usage\"]]\n",
    "df_by_user = df_by_user.sort_index().reset_index(drop=True)\n",
    "\n",
    "## Drop total\n",
    "df_by_user.drop(df_by_user.tail(1).index,inplace=True)\n",
    "\n",
    "## Plot pie\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=1,\n",
    "    specs=[[{\"type\": \"pie\"}]],\n",
    "    subplot_titles=(\"Credits\")\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Pie(labels=df_by_user['user_name'].tolist(), \\\n",
    "                     values=df_by_user['approximate_credits'].tolist(), \\\n",
    "                     name=\"Credits\", rotation=320, \\\n",
    "                     marker_colors=color_scheme),row=1,col=1)\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Total cost by user\",\n",
    "        'y':0.1,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'bottom'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot timeseries\n",
    "df_by_user_ts = df.groupby(['user_name','hourly_start_time']).sum('numeric_only').reset_index()\n",
    "df_by_user_ts = df_by_user_ts[~df_by_user_ts.user_name.isin(df_low_usage_users[\"user_name\"].values)]\n",
    "df_by_user_ts.reset_index(drop=True)\n",
    "fig = px.area(df_by_user_ts,\\\n",
    "              x=\"hourly_start_time\",\\\n",
    "              y=\"approximate_credits\",\\\n",
    "              color=\"user_name\",\\\n",
    "              color_discrete_sequence=color_scheme)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Timeseries of cost by user (except low usage users)\",\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    xaxis_title=\"Hourly start time (UTC)\",\n",
    "    yaxis_title=\"Credits used (approx.)\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost by warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get usage for the past week\n",
    "df = cqlib.cost_by_wh_ts(sdate, edate)\n",
    "df_by_wh = df.groupby(['warehouse_name']).sum('numeric_only').reset_index()\n",
    "df_by_wh = df_by_wh.round(2)\n",
    "\n",
    "\n",
    "## Get usage for previous week as a predictive sanity check\n",
    "df_prev = cqlib.cost_by_wh_ts(p1_sdate, p1_edate)\n",
    "df_by_wh_prev = df_prev.groupby(['warehouse_name']).sum('numeric_only').reset_index()\n",
    "df_by_wh_prev = df_by_wh_prev.round(2)\n",
    "# df_by_wh_prev.loc[len(df.index)] = ['Total', \\\n",
    "#                                df_by_wh_prev['credits'].sum(), \\\n",
    "#                                df_by_wh_prev['cloud_services_credits'].sum()\n",
    "#                               ]\n",
    "df_by_wh_prev.rename(columns = {\"credits\": \"credits_previous_week\",\\\n",
    "                                \"cloud_services_credits\": \"cloud_services_credits_previous_week\"}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "## Get percentage change since previous week\n",
    "df_by_wh.set_index('warehouse_name',inplace=True)\n",
    "df_by_wh_prev.set_index('warehouse_name',inplace=True)\n",
    "df_by_wh = pd.concat([df_by_wh_prev, df_by_wh], axis=1)\n",
    "df_by_wh.reset_index(inplace=True)\n",
    "\n",
    "df_by_wh.loc[len(df_by_wh.index)] = ['Total', \\\n",
    "                                     df_by_wh['credits'].sum(), \\\n",
    "                                     df_by_wh['cloud_services_credits'].sum(), \\\n",
    "                                     df_by_wh['credits_previous_week'].sum(),\\\n",
    "                                     df_by_wh['cloud_services_credits_previous_week'].sum(),\\\n",
    "                                                ]\n",
    "\n",
    "df_by_wh[\"pct_change_credits\"] = round((df_by_wh[\"credits\"]\\\n",
    "                                          -df_by_wh[\"credits_previous_week\"])\\\n",
    "                                         /df_by_wh[\"credits_previous_week\"]*100,2)\n",
    "df_by_wh.fillna({'warehouse_name':'Unassigned',\\\n",
    "                   'credits_previous_week':0,\\\n",
    "                   'cloud_services_credits_previous_week': 0,\\\n",
    "                   'credits':0,\\\n",
    "                   'cloud_service_credits':0,\\\n",
    "                   'pct_change_credits':0\\\n",
    "                  }, inplace=True)\n",
    "\n",
    "df_by_wh_print = df_by_wh[[\"warehouse_name\",\"credits_previous_week\",\"credits\",\"pct_change_credits\"]]\n",
    "\n",
    "\n",
    "print('Warehouses: Credit consumption trends')\n",
    "print('-------------------------------------')\n",
    "print(tabulate(df_by_wh_print, headers='keys', tablefmt='rounded_outline', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last row of totals for the plot\n",
    "df_by_wh.drop(df_by_wh.tail(1).index,inplace=True)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=1,\n",
    "    specs=[[{\"type\": \"pie\"}]],\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Pie(labels=df_by_wh['warehouse_name'].tolist(),\\\n",
    "                     values=df_by_wh['credits'].tolist(),\\\n",
    "                     name='credits',\\\n",
    "                     marker_colors=color_scheme),row=1,col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Total cost by warehouse\",\n",
    "        'y':0.1,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot timeseries\n",
    "df_by_wh_ts = df.groupby(['warehouse_name','hourly_start_time']).sum('numeric_only').reset_index()\n",
    "fig = px.area(df_by_wh_ts, x=\"hourly_start_time\", y=\"credits\", color=\"warehouse_name\",color_discrete_sequence=color_scheme)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Timeseries of cost by warehouse\",\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    xaxis_title=\"Hourly start time (UTC)\",\n",
    "    yaxis_title=\"Credits used\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost by Partner Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get usage for the past week\n",
    "df = cqlib.cost_by_partner_tool_ts(sdate, edate)\n",
    "df_by_pt = df.groupby(['client_application_name']).sum('numeric_only').reset_index()\n",
    "df_by_pt = df_by_pt.round(2)\n",
    "df_by_pt.loc[len(df.index)] = ['Total', df_by_pt['approximate_credits'].sum()]\n",
    "\n",
    "## Get usage for previous week as a predictive sanity check\n",
    "df_prev = cqlib.cost_by_partner_tool_ts(p1_sdate, p1_edate)\n",
    "df_by_pt_prev = df_prev.groupby(['client_application_name']).sum('numeric_only').reset_index()\n",
    "df_by_pt_prev = df_by_pt_prev.round(2)\n",
    "df_by_pt_prev.loc[len(df_prev.index)] = ['Total', df_by_pt_prev['approximate_credits'].sum()]\n",
    "df_by_pt_prev.rename(columns={\"approximate_credits\": \"approximate_credits_previous_week\"}, inplace=True)\n",
    "\n",
    "## Get percentage change since previous week\n",
    "df_by_pt.set_index('client_application_name',inplace=True)\n",
    "df_by_pt_prev.set_index('client_application_name',inplace=True)\n",
    "df_by_pt = pd.concat([df_by_pt_prev, df_by_pt], axis=1)\n",
    "df_by_pt.reset_index(inplace=True)\n",
    "\n",
    "df_by_pt.fillna({'client_application_name':'Unassigned',\\\n",
    "                   'approximate_credits_previous_week':0,\\\n",
    "                   'approximate_credits':0,\\\n",
    "                   'pct_change_credits':0\\\n",
    "                  }, inplace=True)\n",
    "\n",
    "df_by_pt[\"pct_change_credits\"] = round((df_by_pt[\"approximate_credits\"]\\\n",
    "                                          -df_by_pt[\"approximate_credits_previous_week\"])\\\n",
    "                                         /df_by_pt[\"approximate_credits_previous_week\"]*100,2)\n",
    "\n",
    "print('Client Application: Credit consumption trends')\n",
    "print('---------------------------------------------')\n",
    "print(tabulate(df_by_pt, headers='keys', tablefmt='rounded_outline', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last row of totals for the plot\n",
    "df_by_pt.drop(df_by_pt.tail(1).index,inplace=True)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=1,\n",
    "    specs=[[{\"type\": \"pie\"}]],\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Pie(labels=df_by_pt['client_application_name'].tolist(),\\\n",
    "                     values=df_by_pt['approximate_credits'].tolist(),\\\n",
    "                     name='credits',marker_colors=color_scheme,\\\n",
    "                     rotation=45),row=1,col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Breakdown of total cost by partner tools\",\n",
    "        'y':0.1,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_pt_ts = df.groupby(['client_application_name','hourly_start_time']).sum('numeric_only').reset_index()\n",
    "# df_by_pt_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(df_by_pt_ts,\\\n",
    "              x=\"hourly_start_time\",\\\n",
    "              y=\"approximate_credits\",\\\n",
    "              color=\"client_application_name\",\\\n",
    "              color_discrete_sequence=color_scheme,\\\n",
    "             markers=True)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Timeseries of cost by partner tools\",\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    xaxis_title=\"Hourly start time (UTC)\",\n",
    "    yaxis_title=\"Credits used (approx.)\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries at peak usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize query library\n",
    "from optiml.backend.query_profile import QueryProfile\n",
    "from optiml.backend.warehouse_profile import WarehouseProfile\n",
    "qqlib = QueryProfile(connection, schema)\n",
    "whlib = WarehouseProfile(connection, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get queries at usage peaks\n",
    "df = qqlib.get_queries(start_date='2022-10-01 12:00:00',\\\n",
    "                       end_date='2022-10-01 19:00:00',\\\n",
    "                       user='FIVETRAN_USER',\\\n",
    "                       wh=\"PROD_WH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get warehouse events at peak usage\n",
    "df_events = whlib.wh_events(start_datetime='2022-10-01 00:00:00',\\\n",
    "                     end_datetime='2022-10-02 00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events[df_events[\"warehouse_name\"]==\"PROD_WH\"].sort_values(\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = whlib.wh_credits_per_hour(start_datetime='2022-10-01 12:00:00',\\\n",
    "                     end_datetime='2022-10-01 20:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"start_time\", inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(df,\\\n",
    "              x=\"start_time\",\\\n",
    "              y=\"credits_used_compute\",\\\n",
    "              color=\"warehouse_name\",\\\n",
    "              color_discrete_sequence=color_scheme,\\\n",
    "             markers=True)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Timeseries of cost by partner tools\",\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    xaxis_title=\"Hourly start time (UTC)\",\n",
    "    yaxis_title=\"Credits used (approx.)\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "* If the resource monitor did not send a notification last week and the new resource monitor proposed is within 10% of previous monitor - dont update the resource monitor\n",
    "\n",
    "* If the resource monitor sent a notification last week due to an unexplained usage that cannot be attributed to legitimate use continue to debug and dont change the resource monitor\n",
    "    \n",
    "* If the resource monitor sent a notification last week that can be attributed to legitimate use update the resource monitor\n",
    "    \n",
    "* If the new resource monitor values are >10% over last week's values update the resource monitor\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap as tw\n",
    "def generate_resource_monitor_sql(resource_monitor_name=\"monitor_1\",\\\n",
    "                              credit_quota=10,\\\n",
    "                              periodicity=\"weekly\",\\\n",
    "                              start_timestamp_ltz=\"2023-02-18 00:00:00 PST\",\\\n",
    "                              percentage_of_monitor=100,\\\n",
    "                              action=\"notify\",\\\n",
    "                              warehouse_name=\"warehouse_1\"):\n",
    "    \n",
    "    resource_monitor_sql = tw.dedent(f\"\"\"\n",
    "                            USE ROLE ACCOUNTADMIN;\n",
    "                            CREATE OR REPLACE RESOURCE MONITOR {resource_monitor_name} \n",
    "                            WITH CREDIT_QUOTA={credit_quota}\n",
    "                            FREQUENCY={periodicity}\n",
    "                            START_TIMESTAMP={start_timestamp_ltz}\n",
    "                            TRIGGERS ON {percentage_of_monitor} PERCENT DO {action};\n",
    "                            ALTER WAREHOUSE {warehouse_name} SET RESOURCE_MONITOR={resource_monitor_name};\n",
    "                            \"\"\")\n",
    "    return resource_monitor_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "TRAINING_LENGTH = 30\n",
    "training_start = sdate - timedelta(TRAINING_LENGTH + 1)\n",
    "training_end = sdate - timedelta(1)\n",
    "# training_start, training_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resource_monitor_values(ts, te):\n",
    "    df_compute = cqlib.cost_of_compute_ts(ts,te)\n",
    "    df_compute.drop(df_compute.loc[df_compute['warehouse_name']==\"CLOUD_SERVICES_ONLY\"].index, inplace=True)\n",
    "    df_by_wh_day = df_compute.groupby([\n",
    "                 pd.Grouper(key='hourly_start_time', axis=0, freq='D', sort=True),\n",
    "                 pd.Grouper('warehouse_name')\n",
    "               ]).sum()\n",
    "    df_by_wh_day.reset_index(inplace=True)\n",
    "    df_by_wh_day.rename(columns={\"hourly_start_time\": \"day\"}, errors=\"raise\", inplace=True)\n",
    "    df_stats_by_wh_day = df_by_wh_day.groupby(\"warehouse_name\")[\"credits\"].agg(['mean', 'std'])\n",
    "    df_stats_by_wh_day.reset_index(inplace=True)\n",
    "    df_stats_by_wh_day[\"credits_three_sigma_plus\"] = df_stats_by_wh_day[\"mean\"]+3*df_stats_by_wh_day[\"std\"]\n",
    "    df_stats_by_wh_day[\"credits_three_sigma_minus\"] = df_stats_by_wh_day[\"mean\"]-3*df_stats_by_wh_day[\"std\"]\n",
    "    df_stats_by_wh_day[\"credits_three_sigma_minus\"] = df_stats_by_wh_day[\"credits_three_sigma_minus\"].clip(0, None)\n",
    "    df_stats_by_wh_day = df_stats_by_wh_day.round(2)\n",
    "    df_stats_by_wh_day.drop(columns=[\"mean\", \"std\"],inplace=True)\n",
    "    df_stats_by_wh_day.reset_index(inplace=True,drop=True)\n",
    "    return df_by_wh_day, df_stats_by_wh_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_wh, resource_monitor = get_resource_monitor_values(training_start, training_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_monitor_queries = []\n",
    "for idx, wh_name in enumerate(resource_monitor[\"warehouse_name\"].unique()):\n",
    "    resource_monitor_name = resource_monitor.loc[idx][\"warehouse_name\"] + '_RESOURCE_MONITOR'\n",
    "    credit_quota = resource_monitor.loc[idx][\"credits_three_sigma_plus\"]\n",
    "    start_timestamp_ltz = \"YYYY-MM-DD HH:MM:SS PST\"\n",
    "    periodicity = \"DAILY\"\n",
    "    percentage_of_monitor=100\n",
    "    action=\"NOTIFY\"\n",
    "    warehouse_name=resource_monitor.loc[idx][\"warehouse_name\"]\n",
    "    resource_monitor_queries.append(generate_resource_monitor_sql(resource_monitor_name,\\\n",
    "                              credit_quota,\\\n",
    "                              periodicity,\\\n",
    "                              start_timestamp_ltz,\\\n",
    "                              percentage_of_monitor,\\\n",
    "                              action,\\\n",
    "                              warehouse_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Query templates for you to generate resource monitor for this week\")\n",
    "for res_mon_q in resource_monitor_queries:\n",
    "    print(res_mon_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further possible actions on this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "* Cost by tasks if that exists - doesnt seem to for Kiva - would like to understand this usage pattern\n",
    "* Cost by partner tools takes ~3 min for each run for 1 week. Needs to run twice during an analysis. Does this require mitigation? All other queries run in a few sec. each.\n",
    "* Provide recommendation for total resource monitor - weekly\n",
    "* Provide recommendation for resource monitor by day of the week:\n",
    "    * Warehouse\n",
    "    * Overall\n",
    "* Next set of notebooks\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting resource monitor based on data from 2022-10-05 to 2022-10-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get current week compute data\n",
    "current_week_start = datetime.strptime('2022-10-05', '%Y-%m-%d').date()\n",
    "current_week_end = datetime.strptime('2022-10-12', '%Y-%m-%d').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "TRAINING_LENGTH = 30\n",
    "training_start = current_week_start - timedelta(TRAINING_LENGTH + 1)\n",
    "training_end = current_week_start - timedelta(1)\n",
    "# training_start, training_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_wh, resource_monitor = get_resource_monitor_values(training_start, training_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current_week = cqlib.cost_of_compute_ts(current_week_start, current_week_end)\n",
    "df_current_week.drop(df_current_week.loc[df_current_week['warehouse_name']==\"CLOUD_SERVICES_ONLY\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the aggregated credit usage by day\n",
    "df_current_week_by_wh_day = df_current_week.groupby([\n",
    "                 pd.Grouper(key='hourly_start_time', axis=0, freq='D', sort=True),\n",
    "                 pd.Grouper('warehouse_name')\n",
    "               ]).sum()\n",
    "\n",
    "df_current_week_by_wh_day.reset_index(inplace=True)\n",
    "df_current_week_by_wh_day.rename(columns={\"hourly_start_time\": \"day\"}, errors=\"raise\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current_week_by_wh_day = df_current_week_by_wh_day.merge(resource_monitor,\\\n",
    "                                                            left_on='warehouse_name',\\\n",
    "                                                            right_on='warehouse_name',\\\n",
    "                                                            suffixes=('_left', '_right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wh in df_current_week_by_wh_day[\"warehouse_name\"].unique():\n",
    "    print(wh)\n",
    "\n",
    "    f = make_subplots()\n",
    "    trace1 = go.Bar(\n",
    "            x=df_current_week_by_wh_day[df_current_week_by_wh_day[\"warehouse_name\"]==wh][\"day\"],\n",
    "            y=df_current_week_by_wh_day[df_current_week_by_wh_day[\"warehouse_name\"]==wh][\"credits\"],\n",
    "\n",
    "        )\n",
    "\n",
    "    \n",
    "    trace2 = go.Scatter(\n",
    "        x=df_current_week_by_wh_day[df_current_week_by_wh_day[\"warehouse_name\"]==wh][\"day\"],\n",
    "        y=df_current_week_by_wh_day[df_current_week_by_wh_day[\"warehouse_name\"]==wh][\"credits_three_sigma_plus\"],\n",
    "        mode='lines+markers'\n",
    "        )\n",
    "    \n",
    "    \n",
    "\n",
    "    f.add_trace(trace1, secondary_y=False)\n",
    "    f.update_layout(barmode='group')\n",
    "    f.add_trace(trace2, secondary_y=False)\n",
    "    \n",
    "    f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking against warehouse timeseries data for credit usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cqlib.cost_by_wh_ts(current_week_start, current_week_end)\n",
    "## Plot timeseries\n",
    "df_by_wh_ts = df.groupby(['warehouse_name','hourly_start_time']).sum('numeric_only').reset_index()\n",
    "fig = px.area(df_by_wh_ts, x=\"hourly_start_time\", y=\"credits\", color=\"warehouse_name\",color_discrete_sequence=color_scheme)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Timeseries of cost by warehouse\",\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    xaxis_title=\"Hourly start time (UTC)\",\n",
    "    yaxis_title=\"Credits used\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting resource monitor based on data from 2022-09-27 to 2022-10-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get current week compute data\n",
    "current_week_start = datetime.strptime('2022-09-27', '%Y-%m-%d').date()\n",
    "current_week_end = datetime.strptime('2022-10-04', '%Y-%m-%d').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "TRAINING_LENGTH = 30\n",
    "training_start = current_week_start - timedelta(TRAINING_LENGTH + 1)\n",
    "training_end = current_week_start - timedelta(1)\n",
    "# training_start, training_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_wh, resource_monitor = get_resource_monitor_values(training_start, training_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current_week = cqlib.cost_of_compute_ts(current_week_start, current_week_end)\n",
    "df_current_week.drop(df_current_week.loc[df_current_week['warehouse_name']==\"CLOUD_SERVICES_ONLY\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the aggregated credit usage by day\n",
    "df_current_week_by_wh_day = df_current_week.groupby([\n",
    "                 pd.Grouper(key='hourly_start_time', axis=0, freq='D', sort=True),\n",
    "                 pd.Grouper('warehouse_name')\n",
    "               ]).sum()\n",
    "\n",
    "df_current_week_by_wh_day.reset_index(inplace=True)\n",
    "df_current_week_by_wh_day.rename(columns={\"hourly_start_time\": \"day\"}, errors=\"raise\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current_week_by_wh_day = df_current_week_by_wh_day.merge(resource_monitor,\\\n",
    "                                                            left_on='warehouse_name',\\\n",
    "                                                            right_on='warehouse_name',\\\n",
    "                                                            suffixes=('_left', '_right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wh in df_current_week_by_wh_day[\"warehouse_name\"].unique():\n",
    "    print(wh)\n",
    "\n",
    "    f = make_subplots()\n",
    "    trace1 = go.Bar(\n",
    "            x=df_current_week_by_wh_day[df_current_week_by_wh_day[\"warehouse_name\"]==wh][\"day\"],\n",
    "            y=df_current_week_by_wh_day[df_current_week_by_wh_day[\"warehouse_name\"]==wh][\"credits\"],\n",
    "\n",
    "        )\n",
    "\n",
    "    \n",
    "    trace2 = go.Scatter(\n",
    "        x=df_current_week_by_wh_day[df_current_week_by_wh_day[\"warehouse_name\"]==wh][\"day\"],\n",
    "        y=df_current_week_by_wh_day[df_current_week_by_wh_day[\"warehouse_name\"]==wh][\"credits_three_sigma_plus\"],\n",
    "        mode='lines+markers'\n",
    "        )\n",
    "    \n",
    "    \n",
    "\n",
    "    f.add_trace(trace1, secondary_y=False)\n",
    "    f.update_layout(barmode='group')\n",
    "    f.add_trace(trace2, secondary_y=False)\n",
    "    \n",
    "    f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cqlib.cost_by_wh_ts(current_week_start, current_week_end)\n",
    "## Plot timeseries\n",
    "df_by_wh_ts = df.groupby(['warehouse_name','hourly_start_time']).sum('numeric_only').reset_index()\n",
    "fig = px.area(df_by_wh_ts, x=\"hourly_start_time\", y=\"credits\", color=\"warehouse_name\",color_discrete_sequence=color_scheme)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Timeseries of cost by warehouse\",\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    xaxis_title=\"Hourly start time (UTC)\",\n",
    "    yaxis_title=\"Credits used\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "fcbd4ad66d969ea49516a1cf27383420b67e9e950ebdd1bbb64e01b736f968b6"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
