{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f92ea-f7e5-4ad7-bfb9-a06473a72586",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, pathlib\n",
    "sys.path.append(str(pathlib.Path.cwd().parent.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a200a-4722-4654-8242-701e189f6431",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "\n",
    "%dotenv ../../env/.env\n",
    "\n",
    "import warnings\n",
    "from pandas import Timedelta\n",
    "# from optiml.utils import sf\n",
    "import time\n",
    "from optiml.utils.sf import logger, sql_to_df, run_sql, conn, session\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime\n",
    "\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4dcdcf-019a-473f-8c78-9e1a821e4059",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = session._conn._conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd852f-1e42-4ada-a741-c050d9cc60f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.deepcopy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616cd797-536f-4ed1-818e-7245cbb33f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea84b7e-4793-4a1c-a09d-b89f43709b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_query(conn, q):\n",
    "    with conn.cursor() as c:\n",
    "        return exec_query_cursor(c,q)\n",
    "\n",
    "def exec_query_cursor(cursor, q):\n",
    "    print(q)\n",
    "    try:\n",
    "        cursor.execute_async(q)\n",
    "        qid = cursor.sfqid\n",
    "        cursor.get_results_from_sfqid(qid)\n",
    "        results = cursor.fetchall()\n",
    "        print(results)\n",
    "        # all_results[q] = results\n",
    "    except Exception as e:\n",
    "        # all_results[q] = e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0b723d-7f15-4639-a8d1-12e4eaf47fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Python program to illustrate the concept\n",
    "# of threading\n",
    "# importing the threading module\n",
    "import threading\n",
    " \n",
    " \n",
    "def print_cube(num):\n",
    "    # function to print cube of given num\n",
    "    print(\"Cube: {}\" .format(num * num * num))\n",
    " \n",
    " \n",
    "def print_square(num):\n",
    "    # function to print square of given num\n",
    "    print(\"Square: {}\" .format(num * num))\n",
    " \n",
    " \n",
    "all_results = {}\n",
    "\n",
    "# exec_query(conn, 3)\n",
    "    # creating thread\n",
    "numthreads = 10\n",
    "threads = []\n",
    "\n",
    "cursor = conn.cursor()\n",
    "for i in range(numthreads):\n",
    "    print(i)\n",
    "    # threads.append(threading.Thread(target=print_square, args=(i,)))\n",
    "    q = f\"select {i}\"\n",
    "    threads.append(threading.Thread(target=exec_query, args=(conn,q)))\n",
    "    \n",
    "    if i == 4:\n",
    "        q2 = \"bad statement\"\n",
    "    else:\n",
    "        q2 = f\"select 'second {i}'\"\n",
    "    threads.append(threading.Thread(target=exec_query, args=(conn,q2)))\n",
    "    # threads.append(threading.Thread(target=exec_query_cursor, args=(cursor,i)))\n",
    " \n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "    \n",
    "#     # starting thread 1\n",
    "#     t1.start()\n",
    "#     # starting thread 2\n",
    "#     t2.start()\n",
    " \n",
    "#     # wait until thread 1 is completely executed\n",
    "#     t1.join()\n",
    "#     # wait until thread 2 is completely executed\n",
    "#     t2.join()\n",
    " \n",
    "#     # both threads completely executed\n",
    "#     print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0dda80-b244-45cc-8880-6482ac5528f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af7439-6093-40c6-ad2b-b9e80ce4028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_query(conn, q):\n",
    "    with conn.cursor() as c:\n",
    "        return exec_query_cursor(c,q)\n",
    "\n",
    "def exec_query_cursor(cursor, q):\n",
    "    print(f\"running query {q}\")\n",
    "    # try:\n",
    "    cursor.execute_async(q)\n",
    "    qid = cursor.sfqid\n",
    "    cursor.get_results_from_sfqid(qid)\n",
    "    results = cursor.fetchall()\n",
    "    return results\n",
    "        # all_results[q] = results\n",
    "    # except Exception as e:\n",
    "    #     return e\n",
    "        # all_results[q] = e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989b9f9f-b5c1-4511-833e-cfffd4643f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "# Define your graph of functions and dependencies\n",
    "\n",
    "import time\n",
    "\n",
    "# def task(n):\n",
    "#     print(f\"performing task {n}\")\n",
    "#     if n == 2:\n",
    "#         time.sleep(2)\n",
    "#     if n == 2:\n",
    "#         raise ValueError(\"wtf\")\n",
    "#     return n\n",
    "\n",
    "# graph = {\n",
    "#     'node1': {\n",
    "#         'dependencies': [], \n",
    "#         'fn': exec_query,\n",
    "#         'args': (conn, \"select 1\",)\n",
    "#     },\n",
    "#     'node2': {\n",
    "#         'dependencies': [], \n",
    "#         'fn': exec_query,\n",
    "#         'args': (conn, \"select 2\",)\n",
    "#     },\n",
    "#     'node3': {\n",
    "#         'dependencies': ['node2', 'node1'], \n",
    "#         'fn': exec_query,\n",
    "#         'args': (conn, \"select 3\",)\n",
    "#     },\n",
    "#     'node4': {\n",
    "#         'dependencies': ['node1'], \n",
    "#         'fn': exec_query,\n",
    "#         'args': (conn, \"select 4\",)\n",
    "#     }\n",
    "# }\n",
    "\n",
    "graph = {\n",
    "    'node1': {\n",
    "        'dependencies': [], \n",
    "        'fn': exec_query,\n",
    "        'args': (conn, \"create or replace table a as select 1 col\",)\n",
    "    },\n",
    "    'node2': {\n",
    "        'dependencies': ['node1'], \n",
    "        'fn': exec_query,\n",
    "        'args': (conn, \"create or replace table b as select * from a\",)\n",
    "    },\n",
    "    'node3': {\n",
    "        'dependencies': ['node2', 'node1'], \n",
    "        'fn': exec_query,\n",
    "        'args': (conn, \"create or replace table c as select * from a union select * from b\",)\n",
    "    },\n",
    "    'node4': {\n",
    "        'dependencies': ['node1'], \n",
    "        'fn': exec_query,\n",
    "        'args': (conn, \"create or replace table d as select * from a\",)\n",
    "    }\n",
    "}\n",
    "import threading\n",
    "lock = threading.Lock()\n",
    "\n",
    "# Create a dictionary to store the results of each function\n",
    "results = {}\n",
    "errors = {}\n",
    "def run_function(node):\n",
    "    # Check if all dependencies have been completed\n",
    "    # dependencies = graph[node]['dependencies']\n",
    "    # for dependency in dependencies:\n",
    "    #     if dependency not in results:\n",
    "    #         raise ValueError(f\"Dependency {dependency} of node {node} has not been completed\")\n",
    "\n",
    "    # Execute the function and store the result\n",
    "    try:\n",
    "        task_result = graph[node]['fn'](*graph[node]['args'])\n",
    "        with lock:\n",
    "            results[node] = task_result\n",
    "            print(f\"{node} complete; task_result: {task_result}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        task_result = e\n",
    "        with lock:\n",
    "            errors[node] = e\n",
    "\n",
    "import queue\n",
    "task_queue = queue.Queue()\n",
    "\n",
    "# Add the initial tasks to the queue\n",
    "for node in graph:\n",
    "    task_queue.put(node)\n",
    "\n",
    "# Set the maximum number of threads\n",
    "max_threads = 1\n",
    "\n",
    "# Create a ThreadPoolExecutor with the maximum number of threads\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "    # Create a dictionary to store the futures\n",
    "    futures = {}\n",
    "\n",
    "    # Process the tasks from the queue\n",
    "    while not task_queue.empty():\n",
    "        node = task_queue.get()\n",
    "        # print(f\"evaluating node {node}\")\n",
    "        # Check if all dependencies have been completed\n",
    "        dependencies = graph[node]['dependencies']\n",
    "        dependencies_completed = all(dependency in results for dependency in dependencies)\n",
    "        \n",
    "        dependencies_errored = any(dependency in errors for dependency in dependencies)\n",
    "        # print(f\"dependencies complete: {dependencies_completed}\")\n",
    "        if dependencies_completed:\n",
    "            print(f\"dependencies complete for node {node}. Submitting.\")\n",
    "            # Submit the function to the executor\n",
    "            future = executor.submit(run_function, node)\n",
    "            futures[node] = future\n",
    "\n",
    "            # # Add the dependent tasks to the queue\n",
    "            # for dependent_node in graph:\n",
    "            #     if node in graph[dependent_node]['dependencies']:\n",
    "            #         task_queue.put(dependent_node)\n",
    "        elif dependencies_errored:\n",
    "            raise ValueError(f\"dependencies for {node} errored\")\n",
    "        else:\n",
    "            # print(f\"dependencies not complete for node {node}. Submitting.\")\n",
    "            # Re-add the task to the queue for later processing\n",
    "            task_queue.put(node)\n",
    "\n",
    "print(\"waiting for completion...\")\n",
    "# Wait for all futures to complete\n",
    "concurrent.futures.wait(futures.values())\n",
    "\n",
    "# Access the results\n",
    "for node, future in futures.items():\n",
    "    result = future.result()\n",
    "    print(f\"Result of {node}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45654341-c486-42b6-965f-d248fe3e007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a3599-1799-48ab-a963-c75e6293d7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
