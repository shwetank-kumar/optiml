{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fe9cab-eea5-40c4-b396-28b5c6d60242",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, pathlib\n",
    "sys.path.append(str(pathlib.Path.cwd().parent.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d472020-1bc3-4001-836f-08a7036c4b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "\n",
    "%dotenv ../../env/.env\n",
    "\n",
    "import warnings\n",
    "from pandas import Timedelta\n",
    "# from optiml.utils import sf\n",
    "import time\n",
    "from optiml.utils.sf import logger, sql_to_df, run_sql, conn, session\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675e1e88-278b-4e6b-b232-d66cda2b995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import uuid\n",
    "# uuid = str(uuid.uuid4()).replace(\"-\", \"_\")\n",
    "# print(uuid)\n",
    "# wh_name = f\"test_{uuid}\"\n",
    "\n",
    "# create = f\"\"\"\n",
    "# create or replace warehouse {wh_name}\n",
    "# auto_suspend = 60\n",
    "# SCALING_POLICY=STANDARD\n",
    "# INITIALLY_SUSPENDED=true\n",
    "# MAX_CLUSTER_COUNT = 4;\n",
    "# \"\"\"\n",
    "\n",
    "# run_sql(create)\n",
    "\n",
    "wh_name = 'test_bc9a9691_c770_4eb7_96e9_278aac7db0c6'\n",
    "run_sql(f\"use warehouse {wh_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a822f6e2-6cc9-4a10-aa58-69529538575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    |-------------------------|------------------------------------------------------|\n",
    "#   start                    60 sec\n",
    "\n",
    "#    |--|                   |--|                                \n",
    "\n",
    "#    |------|       |---------|    \n",
    "\n",
    "\n",
    "#    |------|              |---------|\n",
    "\n",
    "\n",
    "#    |-------------------------------|    \n",
    "\n",
    "#    |------------------------------------------|      |-------|                |60sec\n",
    "#                                                   S  R                        |S\n",
    "#                                                                  S        \n",
    "#                                                    ===        =================  \n",
    "#    |-----------------------|     |---|\n",
    "#   greedy after one minute:      SR                      S\n",
    "# slightly less greedy                    S\n",
    "\n",
    "import uuid\n",
    "\n",
    "\n",
    "import sched , time\n",
    "\n",
    "def print_time(a='default'):\n",
    "    print(\"From print_time\", time.time(), a)\n",
    "\n",
    "def test_query(table_name, multiplier):\n",
    "    # return f\"\"\"\n",
    "    # create or replace table {table_name} as \n",
    "    # SELECT seq4() col1 , uniform(1, 10, RANDOM(12)) col2 \n",
    "    # FROM TABLE(GENERATOR(ROWCOUNT => {multiplier} * 10000000)) v \n",
    "    # ORDER BY 2;\n",
    "    # \"\"\"\n",
    "    return f\"\"\"\n",
    "    create or replace table {table_name} as \n",
    "    with a as (\n",
    "    SELECT seq4() col1 , uniform(1, 1000000000, RANDOM(12)) col2 \n",
    "    FROM TABLE(GENERATOR(ROWCOUNT => {multiplier} * 10000000)) v\n",
    "    )\n",
    "    select a1.*, a2.col2 as col3\n",
    "    from a a1\n",
    "    left join a a2\n",
    "    on a1.col1 = a2.col2\n",
    "    ORDER BY a1.col2;\n",
    "    \"\"\"\n",
    "import uuid\n",
    "def run_query(multiplier, warehouse=None):\n",
    "    print(\"running query\")\n",
    "    if warehouse:\n",
    "        run_sql(f\"use warehouse {warehouse};\", wait=True)\n",
    "    random_id = str(uuid.uuid4()).replace(\"-\", \"_\")\n",
    "    q = test_query(f\"test_table_{random_id}\", multiplier)\n",
    "    run_sql(q, wait=False)\n",
    "\n",
    "    \n",
    "# def run_query(sec=10, warehouse=None):\n",
    "#     print(\"running query\")\n",
    "#     if warehouse:\n",
    "#         run_sql(f\"use warehouse {warehouse};\", wait=True)\n",
    "#     run_sql(f\"call test_query({sec});\", wait=False)\n",
    "\n",
    "\n",
    "    # PREPARE QUERY SCHEDULE\n",
    "\n",
    "            #    |-------------------------|-------------------------|-------------------------|-------------------------|\n",
    "            #   start                    60 sec\n",
    "\n",
    "            #    |--|                   |--|                         |--|                   |--|\n",
    "\n",
    "# Control        R                          S                   R                         S\n",
    "# Test           R                                                                                                   S\n",
    "\n",
    "initial_offset = 5\n",
    "\n",
    "# QUERY_LENGTH = 10\n",
    "NUM_PARALLEL_QUERIES = 1\n",
    "\n",
    "\n",
    "N = 60\n",
    "numbers = list(range(1, N+1))\n",
    "\n",
    "# workload_start_times = [0, 10, 20, 30] \n",
    "\n",
    "workload_start_times = list(range(1, N+1, 1))\n",
    "print(workload_start_times)\n",
    "\n",
    "s = sched.scheduler(time.time, time.sleep)\n",
    "\n",
    "for i in range(NUM_PARALLEL_QUERIES):\n",
    "    for t in workload_start_times:\n",
    "        offset = initial_offset + t\n",
    "        # QUERY_WAIT = 0 if t < 30 else 10\n",
    "        multiplier = t/5 + 1\n",
    "        s.enter(offset,1,run_query,argument=(multiplier,))\n",
    "\n",
    "for job in s.queue:\n",
    "    print(job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c993d1ea-34f8-4137-a3f5-170aae86d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a795be8d-a335-460a-847e-978ec3407ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# three interventions to try\n",
    "# economy up, standard down\n",
    "# if running_count == max and nothing queued, set max to min; if queries queued again, set max to max again\n",
    "# if num_active has been same for > 1 minute, set num_active to 0\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d32b96-0c17-4b73-a6dc-8f587e640500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_sql(f\"alter warehouse {wh_name} abort all queries\")\n",
    "# run_sql(f\"alter warehouse {wh_name} suspend\")\n",
    "show_df = sql_to_df(\"show warehouses\")\n",
    "show_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8549694-8dbc-4da9-bebf-15aa67c5e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sql(f\"drop warehouse {wh_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071002f5-3616-4f3f-b4b5-e0e213c05995",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdf[['warehouse_name', 'cluster_number', 'start_time', 'exec_start_time', 'end_time', 'query_text', 'query_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54652af3-a8b1-4bf2-8693-8aae0e17df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa3818f-0aa1-48ca-845b-9fcfc7f1c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "queries = f\"\"\"\n",
    "with q as (\n",
    "select \n",
    "    *,\n",
    "      warehouse_name || ':' || cluster_number || ':' || query_id as warehouse_query,\n",
    "    TIMESTAMPADD( millisecond , -execution_time,end_time) as exec_start_time\n",
    "from table(information_schema.query_history_by_warehouse('{wh_name}'))\n",
    "where execution_status != 'RUNNING'\n",
    "and warehouse_size is not null\n",
    "and start_time between '2023-06-01 21:30' and '2023-06-02 11:00'\n",
    "order by start_time desc\n",
    "limit 100\n",
    ")\n",
    "select\n",
    "  'running' as status,\n",
    "  warehouse_query,\n",
    "  warehouse_name,\n",
    "  cluster_number,\n",
    "  exec_start_time as start_time,\n",
    "  end_time,\n",
    "  query_text,\n",
    "  query_id\n",
    "from q\n",
    "union\n",
    "select\n",
    "  'queued' as status,\n",
    "  warehouse_query,\n",
    "  warehouse_name,\n",
    "  cluster_number,\n",
    "  start_time,\n",
    "  exec_start_time as end_time,\n",
    "  query_text,\n",
    "  query_id\n",
    "from q\n",
    "\"\"\"\n",
    "\n",
    "qdf = sql_to_df(queries)\n",
    "display(qdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c341c726-b877-46da-9682-d33c4c662a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[qdf.start_time.min(),qdf.end_time.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a01d017-b86b-4a9e-923b-00fec571f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "\n",
    "qdf['warehouse_query'] = qdf.warehouse_name + \" : \" + qdf.cluster_number.map(str) + \" : \" + qdf.query_id\n",
    "\n",
    "fig = px.timeline(qdf.sort_values(['warehouse_name', 'cluster_number', 'start_time']), \n",
    "                  x_start=\"start_time\", x_end=\"end_time\", y=\"warehouse_query\", \n",
    "                  color='status', \n",
    "                  hover_data=['query_text', 'query_id'])\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    ")\n",
    "fig.update_xaxes(range = [qdf.start_time.min(),qdf.end_time.max()])\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# figures = [\n",
    "#         px.scatter(whe.sort_values('warehouse_name'), x=\"timestamp\", y=\"warehouse_name\", color='event_name'),\n",
    "#         px.timeline(qdf.sort_values(['warehouse_name', 'start_time']), x_start=\"start_time\", x_end=\"end_time\", y=\"warehouse_query\", hover_data=['query_text', 'query_id']),\n",
    "#     ]\n",
    "\n",
    "# fig = make_subplots(rows=len(figures), cols=1, shared_xaxes=True, vertical_spacing=0.05) \n",
    "\n",
    "# for i, figure in enumerate(figures):\n",
    "#     for trace in range(len(figure[\"data\"])):\n",
    "#         fig.append_trace(figure[\"data\"][trace], row=i+1, col=1)\n",
    "\n",
    "# fig.update_xaxes(title_text=\"warehouse events\", row=1, col=1)\n",
    "# fig.update_xaxes(title_text=\"queries\", row=2, col=1)\n",
    "# fig.update_xaxes(showgrid=True,minor=dict(showgrid=True))\n",
    "# fig.update_yaxes(showgrid=True,minor=dict(showgrid=True))\n",
    "# fig.update_xaxes(autorange=True)\n",
    "# fig.update_layout(\n",
    "#     height=800,\n",
    "# )\n",
    "# fig.update_xaxes(type='date', autorange=True)\n",
    "\n",
    "# fig.show()\n",
    "\n",
    "# fig = px.bar(whm[whm.warehouse_name != 'OPS'], y='warehouse_name', x = ['credits_used_compute'], orientation = 'h', title='credits x warehouse')\n",
    "# fig.show()\n",
    "# fig = px.bar(whm, y='warehouse_name', x = ['credits_used_compute', 'credits_used_cloud_services'], orientation = 'h')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e03312-7d23-43ba-8cb1-b691f8fd76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdf.query_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a259a72-ee47-4ee2-baa5-5c7db21fa9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from optiml.utils.sf import snowconn\n",
    "\n",
    " \n",
    "def monitor(target_wh, using_wh, continuous=False):\n",
    "    using_conn = snowconn()\n",
    "    \n",
    "    def show():\n",
    "        run_sql(f\"USE WAREHOUSE {using_wh}\", ctx=using_conn)\n",
    "        show_df = sql_to_df(\"show warehouses\")\n",
    "\n",
    "        queries = f\"\"\"\n",
    "        select \n",
    "        *\n",
    "    from table(information_schema.query_history_by_warehouse('{target_wh}'))\n",
    "    order by start_time desc\n",
    "    limit 10;\n",
    "        \"\"\"\n",
    "        show_df = sql_to_df(\"show warehouses\")\n",
    "        print(show_df[show_df.name == target_wh.upper()].to_string())\n",
    "\n",
    "        queries_df = sql_to_df(queries)\n",
    "        print(show_df[show_df.name == target_wh.upper()].to_string())\n",
    "        print(queries_df.to_string())\n",
    "    \n",
    "    show()\n",
    "    # if continuous:\n",
    "    #     while(True):\n",
    "            \n",
    "\n",
    "monitor(\"test\", \"demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9baab-82fb-4597-8a36-8a0e702e1be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
