{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fe9cab-eea5-40c4-b396-28b5c6d60242",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, pathlib\n",
    "sys.path.append(str(pathlib.Path.cwd().parent.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d472020-1bc3-4001-836f-08a7036c4b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "\n",
    "%dotenv ../../env/.env\n",
    "\n",
    "import warnings\n",
    "from pandas import Timedelta\n",
    "# from optiml.utils import sf\n",
    "import time\n",
    "from optiml.utils.sf import logger, sql_to_df, run_sql, conn, session\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc268fe9-922b-4ae8-8cb6-299c155b0f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: if Cluster 1 and 3 are active, 2 is idle, and num_clusters is set to 2, does #2 shutoff?\n",
    "#    1b) are credits saved?\n",
    "# Q2: if cluster 1 and 2 are active, and 2 is shutoff before 60 seconds of uptime, are we billed\n",
    "#     at minimum of 60 secs like base warehouse cluster? or charged for usage?\n",
    "#     - yes, minimum of 60 secs billed\n",
    "\n",
    "# algos:\n",
    "# 1) if warehouse is idle, shut down warehouse\n",
    "# 2) estimate total number of active clusters\n",
    "#   a) use total number of running queries\n",
    "#   b) use total pct of provisioned \n",
    "# set max_clusters to that number of active clusters\n",
    "# 3) if multicluster type is STANDARD and warehouse is idle set to ECONOMY\n",
    "#    if not idle and total active clusters > 1 (or total active clusters = max clusters)\n",
    "#        then set to ECONOMY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c6dc4d-e1f3-485e-a0ea-c7db398c7b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c78b84c-23f4-4ea4-9b14-c6bb744b9a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidental runs of the same scenario (no warehouse mgmt; standard scaling policy); shows unexpected variations!\n",
    "wh_names =  ['test_control_a67fc85c_9de9_400e_8e49_6c93dfcef9db',\n",
    " 'test_suspend_idle_after_one_minute_63fcffb5_6a18_4e6c_bb59_824a2a1862b2',\n",
    " 'test_minimize_clusters_if_no_queuing_ec3ecce1_6661_4d0d_a93c_f5b678be9a19',\n",
    " 'test_economy_53142176_000d_4587_8911_4a6115c4ebac',\n",
    " 'test_economy_up_standard_down_e9316185_aea0_4325_ba8c_775c3ad551ed']\n",
    "\n",
    "path = 'test_control_a67fc85c_9de9_400e_8e49_6c93dfcef9db_2023_0614_013902.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e6896b-603a-4af3-aed9-5ef2fe435277",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c990ec50-2c09-42bb-a28d-ecabc44b1de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # wh_name='DEMO'\n",
    "# for wh_name in wh_names:\n",
    "#     print(wh_name.upper())\n",
    "#     import plotly.express as px\n",
    "#     fig = px.line(df[df.name == wh_name.upper()], x='ts', y='started_clusters')\n",
    "#     fig.show()\n",
    "#     fig = px.line(df[df.name == wh_name.upper()], x='ts', y=['running', 'queued'])\n",
    "#     fig.show()\n",
    "#     fig = px.line(df[df.name == wh_name.upper()], x='ts', y=['available', 'provisioning', 'quiescing'])\n",
    "#     fig.update_yaxes(autorange=\"reversed\")\n",
    "\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d3c59c-2e64-44ef-82d4-ef4f019ef6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sql(\"set lookback_days=2\")\n",
    "wh_status = f\"\"\"with qh as (\n",
    "select \n",
    "    *,\n",
    "    md5(warehouse_name) as warehouse_id,\n",
    "      warehouse_name || ':' || cluster_number || ':' || query_id as warehouse_query,\n",
    "    TIMESTAMPADD( millisecond , -execution_time,end_time) as execution_start_time\n",
    "from table(information_schema.query_history_by_user('saf', result_limit=>10000))\n",
    "where execution_status != 'RUNNING'\n",
    "and warehouse_size is not null\n",
    "and start_time > dateadd('days',-$lookback_days, current_timestamp())\n",
    "order by start_time desc\n",
    "),\n",
    "seconds as (\n",
    "    select\n",
    "        dateadd(\n",
    "            'second',\n",
    "            '-' || row_number() over (order by seq4() asc),\n",
    "            dateadd('day', '+1', date_trunc('second', current_timestamp))\n",
    "        ) as second_start,\n",
    "        dateadd('second', '+1', second_start) as timestamp\n",
    "    from table(generator(rowcount => (3600*24 * 100)))\n",
    "    qualify second_start between (select min(start_time) from qh) and (select max(end_time) from qh)\n",
    "),\n",
    "warehouse_cluster_seconds as (\n",
    "    select * from \n",
    "    seconds\n",
    "    cross join \n",
    "    (select distinct md5(warehouse_name) as warehouse_id, warehouse_name, cluster_number from qh) w\n",
    "\n",
    ")\n",
    "-- select * from warehouse_seconds;\n",
    "select\n",
    "    seconds.timestamp,\n",
    "    seconds.warehouse_name,\n",
    "    seconds.warehouse_id,\n",
    "    seconds.cluster_number,\n",
    "    count(queries.query_id) as num_queries\n",
    "from warehouse_cluster_seconds seconds\n",
    "left join qh as queries\n",
    "    -- on date_trunc('hour', seconds.timestamp)=queries.query_hour -- NEW: equi-join condition\n",
    "    on seconds.warehouse_id = queries.warehouse_id\n",
    "    and seconds.cluster_number = queries.cluster_number\n",
    "    and seconds.timestamp -- range join condition\n",
    "      between date_trunc('second', queries.execution_start_time) and date_trunc('second', queries.end_time)\n",
    "group by 1,2,3,4\n",
    "\"\"\"\n",
    "\n",
    "wdf = sql_to_df(wh_status)\n",
    "display(wdf)\n",
    "\n",
    "\n",
    "events = f\"\"\"\n",
    "select *\n",
    "from snowflake.account_usage.warehouse_events_history\n",
    "where timestamp > dateadd('days',-$lookback_days, current_timestamp())\n",
    "\"\"\"\n",
    "\n",
    "whedf = sql_to_df(events)\n",
    "display(whedf)\n",
    "\n",
    "statuses = sql_to_df(\"\"\"\n",
    "with a as (\n",
    "select \n",
    "    *,\n",
    "    md5(warehouse_name) as warehouse_id,\n",
    "      warehouse_name || ':' || cluster_number || ':' || query_id as warehouse_query,\n",
    "    TIMESTAMPADD( millisecond , -execution_time,end_time) as execution_start_time\n",
    "from table(information_schema.query_history_by_user('saf', result_limit=>10000))\n",
    "where execution_status != 'RUNNING'\n",
    "and warehouse_size is not null\n",
    "and start_time > dateadd('days',-$lookback_days, current_timestamp())\n",
    ")\n",
    "select\n",
    "    warehouse_name,\n",
    "    execution_status,\n",
    "    count(*)\n",
    "from a \n",
    "    group by 1,2\n",
    "\"\"\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48421a19-5bb0-4115-9368-7970d93e5d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b958d-dc7a-428a-be01-3d1079babd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# qdf['warehouse_query'] = qdf.warehouse_name + \" : \" + qdf.query_id\n",
    "\n",
    "wdf['timestamp_est'] = wdf.timestamp + pd.Timedelta(hours=3)\n",
    "whedf['timestamp_est'] = whedf.timestamp + pd.Timedelta(hours=3)\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "# fig = px.line(df[df.name == wh_name.upper()], x='ts', y='started_clusters')\n",
    "# fig.show()\n",
    "# fig = px.line(df[df.name == wh_name.upper()], x='ts', y=['running', 'queued'])\n",
    "# fig.show()\n",
    "# fig = px.line(df[df.name == wh_name.upper()], x='ts', y=['available', 'provisioning', 'quiescing'])\n",
    "# fig.update_yaxes(autorange=\"reversed\")\n",
    "\n",
    "# fig.show()\n",
    "\n",
    "# wh_name = wh_names[0]\n",
    "\n",
    "wh_name_subset = wh_names # wh_names[0:1]\n",
    "figures = []\n",
    "for wh_name in wh_name_subset:\n",
    "    print(wh_name)\n",
    "    wh_figures = [\n",
    "        px.line(df[df.name == wh_name.upper()], x='ts', y='started_clusters', title=wh_name.upper()),\n",
    "        px.line(df[df.name == wh_name.upper()], x='ts', y=['running', 'queued']),\n",
    "        px.line(df[df.name == wh_name.upper()], x='ts', y=['available', 'provisioning', 'quiescing']),\n",
    "        # px.scatter(whedf[whedf.warehouse_name == wh_name.upper()].sort_values('warehouse_name'), x=\"timestamp_est\", y=\"event_name\", color='event_name', hover_data=['cluster_number', 'event_name', 'event_reason']),\n",
    "        px.area(wdf[wdf.warehouse_name == wh_name.upper()].sort_values(['timestamp_est', 'cluster_number']), x='timestamp_est', y=['num_queries'], color='cluster_number'),\n",
    "    ]\n",
    "    figures = wh_figures\n",
    "    # figures.extend(wh_figures)\n",
    "    \n",
    "    fig = make_subplots(rows=len(figures), cols=1, shared_xaxes=True, vertical_spacing=0.02) \n",
    "\n",
    "    for i, figure in enumerate(figures):\n",
    "        print(i)\n",
    "        for trace in range(len(figure[\"data\"])):\n",
    "            fig.append_trace(figure[\"data\"][trace], row=i+1, col=1)\n",
    "            fig.update_xaxes(range=[df.ts.min() - pd.Timedelta(seconds=20), df.ts.max()], row=i+1, col=1)\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_xaxes(showgrid=True,minor=dict(showgrid=True))\n",
    "    fig.update_yaxes(showgrid=True,minor=dict(showgrid=True))\n",
    "\n",
    "    # fig.update_layout(height=len(wh_name_subset)*1000)\n",
    "    fig.update_layout(height=1000)\n",
    "    fig.update_xaxes(type='date')\n",
    "    fig.update_yaxes(row=3, col=1, autorange='reversed')\n",
    "\n",
    "\n",
    "    fig.show()\n",
    "print(\"done\")\n",
    "# next: try just one layer of test query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b0d5bb-92f1-46db-ae5b-9ea97e41e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spend_sql = \"\"\"\n",
    "    select * \n",
    "from table(information_schema.WAREHOUSE_METERING_HISTORY( \n",
    "    date_range_start => dateadd('days',-2,current_date())   \n",
    "    )\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "spend_df = sql_to_df(spend_sql)\n",
    "# display(spend_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe333f-f024-4599-8dd2-f6b025cdcb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spend_df[spend_df.warehouse_name.str.lower().isin(wh_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2429f2-791d-4b14-a8ae-de12c8d0431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.bar(spend_df[spend_df.warehouse_name.str.lower().isin(wh_names)], x = 'start_time', y = 'credits_used', color='warehouse_name', barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d875d123-e97f-4536-ace6-70ed06916709",
   "metadata": {},
   "outputs": [],
   "source": [
    "statuses = \"\"\"\n",
    "with a as (\n",
    "select \n",
    "    *,\n",
    "    md5(warehouse_name) as warehouse_id,\n",
    "      warehouse_name || ':' || cluster_number || ':' || query_id as warehouse_query,\n",
    "    TIMESTAMPADD( millisecond , -execution_time,end_time) as execution_start_time\n",
    "from table(information_schema.query_history_by_user('saf', result_limit=>10000))\n",
    "where execution_status != 'RUNNING'\n",
    "and warehouse_size is not null\n",
    "and start_time > dateadd('days',-$lookback_days, current_timestamp())\n",
    ")\n",
    "select\n",
    "    warehouse_name,\n",
    "    execution_status,\n",
    "    count(*) num_queries\n",
    "from a \n",
    "    group by 1,2;\n",
    "    \"\"\"\n",
    "statuses_df = sql_to_df(statuses)\n",
    "import plotly.express as px\n",
    "fig = px.bar(statuses_df[statuses_df.warehouse_name.str.lower().isin(wh_names)], x = 'warehouse_name', y = 'num_queries', color='execution_status', barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab092535-175e-46a2-8f7e-92d0458261a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
