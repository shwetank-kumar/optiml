{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45cf647-2b77-466a-bb98-95e845dc11eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd29c5e-d455-4ef7-a4fd-2b4a61eb1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext dotenv\n",
    "\n",
    "# %dotenv ../../env/.env\n",
    "\n",
    "# import warnings\n",
    "# import utils\n",
    "# from pandas import Timedelta\n",
    "# import time\n",
    "# from utils import logger, sql_to_df, run_sql, session, conn\n",
    "# import pandas as pd\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# try:\n",
    "#     %load_ext autotime\n",
    "# except:\n",
    "#     !pip install ipython-autotime\n",
    "#     %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d63841-80d3-4b84-a45a-aaacdcbcdaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd9ed9-e9e8-403f-b8ef-02e54611636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # warehouse_ids = [41,42,43]\n",
    "# warehouse_ids = [38,39,40]\n",
    "# joined = ','.join([str(w) for w in warehouse_ids])\n",
    "# sql_str = f\"({joined})\"\n",
    "\n",
    "# sql = f\"\"\"\n",
    "# select \n",
    "#     warehouse_id, \n",
    "#     era_start, \n",
    "#     era_end\n",
    "# from query_era_test\n",
    "\n",
    "# -- where warehouse_id in {sql_str}\n",
    "# order by era_start asc\n",
    "# \"\"\"\n",
    "\n",
    "# df = sql_to_df(sql)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ca21ad-b284-47b0-be0e-4e4f1d1498e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for warehouse_id in df.warehouse_id.unique():\n",
    "    print(warehouse_id)\n",
    "    wh_df = df[df.warehouse_id == warehouse_id].sort_values('era_start', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f97c05-2982-47ea-a6a1-958ecb130897",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.timedelta_range(wh_df.era_start.min(), wh_df.era_end.max(), freq=\"1min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a8f89-c520-42ee-b584-3840cd19365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Timestamp\n",
    "query_eras = \\\n",
    "[(Timestamp('2023-04-10 16:44:00'), Timestamp('2023-04-10 16:44:10')),\n",
    " (Timestamp('2023-04-10 16:44:15'), Timestamp('2023-04-10 16:44:25')),\n",
    " (Timestamp('2023-04-10 16:44:55'), Timestamp('2023-04-10 16:45:05')),\n",
    " (Timestamp('2023-04-10 16:45:15'), Timestamp('2023-04-10 16:45:25'))]\n",
    "\n",
    "qdf = pd.DataFrame(query_eras, columns=['era_start', 'era_end'])\n",
    "qdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd903f6-b7f3-4c83-ab4d-78bc0dc08bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bbd44c-8458-4470-9e88-a66e7fa619ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.snowpark.functions as F\n",
    "import snowflake.snowpark.dataframe\n",
    "\n",
    "polling_sec = 1\n",
    "# where warehouse_id in (\n",
    "#     select warehouse_id from (\n",
    "#         select top 10\n",
    "#             warehouse_id,\n",
    "#             warehouse_name,\n",
    "#             sum(dollars_used)\n",
    "#         from warehouse_metering_history_enriched\n",
    "#         group by 1,2 order by 3 desc\n",
    "#     )\n",
    "\n",
    "\n",
    "def greedy_suspend(query_eras, autosuspend_sec):\n",
    "    started = False\n",
    "    resumed_on = None\n",
    "    previous_end = None\n",
    "    dt = Timedelta(seconds=autosuspend_sec)\n",
    "    events = []\n",
    "    for (start, end) in query_eras:\n",
    "        # first process events between previous_end and start\n",
    "        # suspend happens at: \n",
    "        # previous_end + 2*polling_period, as long as we're after resumed_on + 60 + 2*polling_period, \n",
    "        if started:\n",
    "            timediff = start - previous_end \n",
    "            if timediff > dt:\n",
    "                suspend_time = previous_end + dt\n",
    "                started = False\n",
    "                events.append((suspend_time, 'suspend'))\n",
    "\n",
    "        if not started:\n",
    "            started = True\n",
    "            resumed_on = start\n",
    "            events.append((resumed_on, 'resume'))\n",
    "\n",
    "        previous_end = end\n",
    "    \n",
    "    if started:\n",
    "        suspend_time = previous_end + dt\n",
    "        started = False\n",
    "        events.append((suspend_time, 'suspend')) \n",
    "        \n",
    "    events_df = pd.DataFrame(events, columns=['timestamp', 'event_type'])\n",
    "    return events_df\n",
    "\n",
    "def snowflake_suspend(query_eras, autosuspend_sec):\n",
    "#     dt = Timedelta(seconds=autosuspend_sec)\n",
    "#     sixty = Timedelta(seconds=60)\n",
    "    return greedy_suspend(query_eras, max(autosuspend_sec, 30))\n",
    "\n",
    "def smart_suspend(query_eras, polling_sec):\n",
    "    started = False\n",
    "    running = 0\n",
    "    resumed_on = None\n",
    "\n",
    "    previous_end = None\n",
    "    resumed_plus_sixty = None\n",
    "    events = []\n",
    "    for (start, end) in query_eras:\n",
    "        \n",
    "        # first process events between previous_end and start\n",
    "        # suspend happens at: \n",
    "        # previous_end + 2*polling_period, as long as we're after resumed_on + 60 + 2*polling_period, \n",
    "\n",
    "        if started:\n",
    "            first_check_after_previous_end = previous_end + 1*Timedelta(seconds=polling_sec)\n",
    "            earliest_possible_suspend = max(first_check_after_previous_end, resumed_plus_sixty)\n",
    "            if earliest_possible_suspend < start:\n",
    "                started = False\n",
    "                events.append((earliest_possible_suspend, 'suspend'))\n",
    "\n",
    "        if not started:\n",
    "            started = True\n",
    "            resumed_on = start\n",
    "            resumed_plus_sixty = resumed_on + Timedelta(seconds=60)\n",
    "            events.append((resumed_on, 'resume'))\n",
    "\n",
    "        previous_end = end\n",
    "    \n",
    "    if started:\n",
    "        first_check_after_previous_end = previous_end + 1*Timedelta(seconds=polling_sec)\n",
    "        earliest_possible_suspend = max(first_check_after_previous_end, resumed_plus_sixty)\n",
    "        events.append((earliest_possible_suspend, 'suspend'))\n",
    "\n",
    "\n",
    "    events_df = pd.DataFrame(events, columns=['timestamp', 'event_type'])\n",
    "    return events_df\n",
    "\n",
    "def wh_events_sim(df):\n",
    "    warehouse_event_dfs = []\n",
    "    for warehouse_id in df.warehouse_id.unique():\n",
    "        print(warehouse_id)\n",
    "        wh_df = df[df.warehouse_id == warehouse_id].sort_values('era_start', ascending=True)\n",
    "\n",
    "        eras = list(zip(wh_df.era_start, wh_df.era_end))\n",
    "\n",
    "        strategy = {'type': 'greedy_after_one_min', 'polling_sec': polling_sec}\n",
    "\n",
    "        events_df = smart_suspend(eras, polling_sec)\n",
    "        events_df['strategy'] = str(strategy)\n",
    "        events_df['warehouse_id'] = warehouse_id\n",
    "        warehouse_event_dfs.append(events_df)\n",
    "\n",
    "        # autosuspend_sec = 60\n",
    "        for autosuspend_sec in [30, 60, 120]:\n",
    "\n",
    "            strategy = {'type': 'greedy', 'autosuspend_sec': autosuspend_sec}\n",
    "            # print(strategy)\n",
    "            events_df = greedy_suspend(eras, autosuspend_sec)\n",
    "            events_df['strategy'] = str(strategy)\n",
    "            events_df['warehouse_id'] = warehouse_id\n",
    "            warehouse_event_dfs.append(events_df)\n",
    "\n",
    "            strategy = {'type': 'snowflake', 'autosuspend_sec': autosuspend_sec}\n",
    "            # print(strategy)\n",
    "            events_df = snowflake_suspend(eras, autosuspend_sec)\n",
    "            events_df['strategy'] = str(strategy)\n",
    "            events_df['warehouse_id'] = warehouse_id\n",
    "            warehouse_event_dfs.append(events_df)\n",
    "\n",
    "    final_df = pd.concat(warehouse_event_dfs)\n",
    "\n",
    "    def uppercase_all_columns(df: snowflake.snowpark.dataframe) -> snowflake.snowpark.dataframe:\n",
    "        return df.select([F.col(column).as_(column.upper()) for column in df.columns])\n",
    "\n",
    "    final_df.timestamp = final_df.timestamp.map(str)\n",
    "    return final_df\n",
    "#     df = session.create_dataframe(final_df)\n",
    "#     uppercase_all_columns(df).write.mode(\"overwrite\").save_as_table(\"wh_events_sim_python\")\n",
    "\n",
    "\n",
    "fast_simulation_df = smart_suspend(query_eras, 1)\n",
    "fast_simulation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb986e-1baa-4d3c-af33-8fb4d9825a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "ts = pd.date_range(qdf.era_start.min(), qdf.era_end.max() + pd.Timedelta(minutes=1.5), freq='1S')\n",
    "df_time = pd.DataFrame(ts, columns=['ts'])\n",
    "df_time\n",
    "\n",
    "df = duckdb.query(\"\"\"\n",
    "with timeseries as (\n",
    "    select * from df_time\n",
    ")\n",
    "select\n",
    "    ts,\n",
    "    count(era_start) > 0 as active\n",
    "from \n",
    "    timeseries t\n",
    "left join qdf \n",
    "on t.ts between qdf.era_start and qdf.era_end\n",
    "group by 1\n",
    "order by ts\n",
    "\"\"\").df()\n",
    "\n",
    "df\n",
    "\n",
    "import plotly.express as px\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='ts',\n",
    "    y='active'\n",
    ")\n",
    "fig.update_yaxes(autorange=\"reversed\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442b342-7c06-4435-bacf-b938cb6b7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# state = list(zip(df.timestamp, df.eras_found))\n",
    "\n",
    "# def wh_events_simulated(wh_activity_series):\n",
    "\n",
    "state = list(zip(df.ts, df.active))\n",
    "started = False\n",
    "events = []\n",
    "\n",
    "def maybe_suspend(started, active, time_since_resumed):\n",
    "    # smart shutdown\n",
    "    return started and (not active) and (time_since_resumed >= Timedelta(seconds=60))\n",
    "\n",
    "for (ts, active) in state:\n",
    "    # print(f\"{ts}, {active}\")\n",
    "    if active and not started:\n",
    "        started = True\n",
    "        resumed_on = ts\n",
    "        events.append((ts, 'resume'))\n",
    "\n",
    "    if maybe_suspend(started, active, ts - resumed_on):\n",
    "        started = False\n",
    "        events.append((ts, 'suspend'))\n",
    "\n",
    "test_events_df = pd.DataFrame(events, columns=['timestamp', 'event_type'])\n",
    "test_events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254095ee-7f46-48e8-bfd7-105746f0c4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_events = [\n",
    " {'timestamp': Timestamp('2023-04-10 16:44:00'), 'event_type': 'resume'},\n",
    " {'timestamp': Timestamp('2023-04-10 16:45:06'), 'event_type': 'suspend'},\n",
    " {'timestamp': Timestamp('2023-04-10 16:45:15'), 'event_type': 'resume'},\n",
    " {'timestamp': Timestamp('2023-04-10 16:46:15'), 'event_type': 'suspend'}\n",
    "]\n",
    "\n",
    "expected_df = pd.DataFrame.from_dict(expected_events)\n",
    "\n",
    "pd.testing.assert_frame_equal(test_events_df, expected_df)\n",
    "pd.testing.assert_frame_equal(fast_simulation_df, expected_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a34dd9e-26dd-4ad4-b5be-bf028a1078ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sql_to_df(\"show warehouses\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7775b257-b3d0-4179-af62-992fc2af194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "managed = {\n",
    "       \"account\": [\n",
    "            'DEMO'\n",
    "       ]\n",
    "}\n",
    "\n",
    "def maybe_suspend_warehouses(whs):\n",
    "    logger.info(\"======== processing warehouses ===============================================================================================\\n\")\n",
    "    df = sql_to_df(\"show warehouses\")\n",
    "    states = df.set_index('name', drop=False).to_dict('index')\n",
    "    \n",
    "    for wh in whs:\n",
    "        logger.info(f\"======== processing warehouse {wh} ===============================================================================================\\n\")\n",
    "        status = states[wh]\n",
    "        started = status['state'] == 'STARTED'\n",
    "        resumed_on = status['resumed_on']\n",
    "        time_since_resumed = pd.Timestamp.utcnow() - resumed_on\n",
    "        active = (status['running'] + status['queued']) > 0\n",
    "        \n",
    "        logger.info(f\"started {started} | active {active} | time_since_resumed {time_since_resumed}\")\n",
    "\n",
    "        suspend = maybe_suspend(started, active, time_since_resumed) \n",
    "        if suspend:\n",
    "            wh = status['name']\n",
    "            logger.info(f\"SUSPENDING WAREHOUSE {wh}\")\n",
    "            # run_sql(f\"ALTER WAREHOUSE {wh} SUSPEND\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf4f56a-5ed5-4a2b-ab6f-dff862653137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "print(\"Number of active threads:\", threading.active_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52345349-493f-4b2a-bf84-e1cb5e35f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    time.sleep(1)\n",
    "    maybe_suspend_warehouses(managed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c504814-9593-40be-80f1-7a30d4e2d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "duckdb.query(\"select * from wh_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb44e9-1b79-47a9-a708-2944ed6fb4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.query(\"\"\"\n",
    "select  * from\n",
    "generate_series(\n",
    "        (select min(era_start) from wh_df),\n",
    "        (select max(era_end) from wh_df),\n",
    "        interval 1 second\n",
    "    );\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d83f75a-9dfc-4cb8-8120-8a9328ac2487",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.query(\"\"\"\n",
    "SELECT \n",
    "* \n",
    "FROM \n",
    "generate_series(\n",
    "    (select min(era_start) from wh_df)::timestamp,\n",
    "    TIMESTAMP '2021-11-29', \n",
    "    INTERVAL 1 DAY\n",
    ");\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795621ad-5d1b-4d7e-b11d-fd124f5edd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.query(\"\"\"\n",
    "SELECT * FROM generate_series(TIMESTAMP '2021-01-01', TIMESTAMP '2021-11-29', INTERVAL 1 DAY);\n",
    "\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
